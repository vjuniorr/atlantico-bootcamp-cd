{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca5c9e3-9a65-42bc-9aa7-2693ae5b6f7c",
   "metadata": {},
   "source": [
    "# 1 - Explicações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2483f-8303-48a4-8b3b-22493a72f7af",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.1 - Bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe8ebf-6bed-4b16-a75f-98979532f3e1",
   "metadata": {},
   "source": [
    "Bag-of-words é uma representação usada para o processamento de linguagem natural e recuperação de informações. Nesse modelo, um texto qualquer é representado como uma bolsa de palavras, de onde vem o nome, não levando em conta a ordem ou a estrutura das palavras no texto, logo não importa em qual linguagem está o texto, ele se baseia se a palavra aparece ou qual a sua frequência."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d30239-4ee1-45ae-bbe0-2884872571ee",
   "metadata": {},
   "source": [
    "## 1.2 - TF-IDF (Term Frequency Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fae97c-4ed6-43ee-b1a4-5797129c713c",
   "metadata": {},
   "source": [
    "TF-IDF é um conjunto de medidas estatísticas para medir o quão importante uma palavra é em um documento. Com ele nós podemos perceber a importancia de uma palavra por meio de uma pontuação, essa pontuação é feita utilizando duas metricas <br>\n",
    "**Term Frequency**: Mede a frequência com que o termo ocorre em um documento <br>\n",
    "**Inverse Document Frequency**: Mede o quão importante um termo é no contexto de todos os documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9aa31-9aea-4cb1-8a9d-7afec815f5ec",
   "metadata": {},
   "source": [
    "# 2 - Praticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ac3da7-55e8-40cf-b795-69fc6a85e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importando as bibliotecas utilizadas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bebae05-7764-4467-967a-be29d3d08ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [\n",
    "    \"John likes\",\n",
    "    \"likes to\",\n",
    "    \"to watch\",\n",
    "    \"watch movies\",\n",
    "    \"Mary likes\",\n",
    "    \"likes movies\",\n",
    "    \"movies too\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f674471b-8553-4d12-b612-b3af98d227da",
   "metadata": {},
   "source": [
    "## 2.1 - Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e310cd6d-f1b9-4313-a49b-41264e952bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow = vectorizer.fit_transform(frases)\n",
    "bow.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ed4141-2a16-4280-b816-04e09fc6504a",
   "metadata": {},
   "source": [
    "## 2.2 - TF-IDF (Term Frequency Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83c6c47-fecd-475f-9f18-fe1cefd97078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85141699, 0.52448938, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.59594003, 0.        , 0.        , 0.80302894,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.70710678,\n",
       "        0.        , 0.70710678],\n",
       "       [0.        , 0.        , 0.        , 0.64974959, 0.        ,\n",
       "        0.        , 0.76014832],\n",
       "       [0.        , 0.52448938, 0.85141699, 0.        , 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.65559486, 0.        , 0.75511282, 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.57866699, 0.        ,\n",
       "        0.81556393, 0.        ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(frases)\n",
    "tfidf.toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
